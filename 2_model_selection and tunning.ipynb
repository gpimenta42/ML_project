{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import itertools\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train_new_feats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = [[f\"target_{i}\" for i in range(1, 9)] + [\"Claim Injury Type\"] + [\"WCB Decision\"] + [\"Agreement Reached\"] + [\"Claim Injury Type_encoded\"]]\n",
    "target = [item for sublist in target for item in sublist]\n",
    "target\n",
    "\n",
    "binary_target = [f\"target_{i}\" for i in range(1, 9)]\n",
    "\n",
    "original_target  = [col for col in target if col not in binary_target]\n",
    "\n",
    "ordinal_target = [\"Claim Injury Type_encoded\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [feat for feat in df.columns if feat not in target]\n",
    "\n",
    "features = [feat for feat in features if df[feat].dtype != \"datetime64[ns]\"]\n",
    "\n",
    "num_feats = [feat for feat in features if df[feat].dtype != \"object\"]\n",
    "\n",
    "cat_feats = [feat for feat in features if df[feat].dtype == \"object\"]\n",
    "cat_feats_index = [features.index(feat) for feat in cat_feats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "selected_features = [\n",
    "    'Age at Injury',\n",
    "    'Attorney/Representative',\n",
    "    'IME-4 Count',\n",
    "    'Accident Date_year',\n",
    "    'Accident Date_assembly_gap_days',\n",
    "    'C3-C2_gap_days',\n",
    "    'C2_missing',\n",
    "    'C3_missing',\n",
    "    'C3_Accident_gap_weeks',\n",
    "    'Hearing_C3 gap_months',\n",
    "    'Hearing_C2 gap_months',\n",
    "    'Days to Assembly',\n",
    "    'Days to First Hearing',\n",
    "    'Average Weekly Wage_log',\n",
    "    'Carrier Name_encoded',\n",
    "    'County of Injury_encoded',\n",
    "    'Industry Code Description_encoded',\n",
    "    'WCIO Cause of Injury Description_encoded',\n",
    "    'WCIO Nature of Injury Description_encoded',\n",
    "    'WCIO Part Of Body Description_encoded',\n",
    "    'Zip Code_encoded',\n",
    "    'County of Worker_encoded',\n",
    "    'Carrier Name_freq',\n",
    "    'County of Injury_freq',\n",
    "    'District Name_freq',\n",
    "    'Industry Code Description_freq',\n",
    "    'WCIO Cause of Injury Description_freq',\n",
    "    'WCIO Nature of Injury Description_freq',\n",
    "    'WCIO Part Of Body Description_freq',\n",
    "    'Zip Code_freq',\n",
    "    'County of Worker_freq'\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "naive_features = [feat.replace(\"_encoded\", \"\") for feat in selected_features]\n",
    "naive_features = [feat.replace(f\"_freq\", \"\") for feat in naive_features]\n",
    "naive_features = set(naive_features)\n",
    "naive_features = list(naive_features)\n",
    "\n",
    "cat_feats = [feat for feat in naive_features if feat in cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {'C': [1], \"solver\":[\"lbfgs\"], \"class_weight\":[None, \"balanced\"]}\n",
    "nb_params = {\"var_smoothing\": [1e-9, 0.1]}\n",
    "#knn_params = {'weights' : ['uniform','distance'], \"n_neighbors\":[5, 7]}\n",
    "rfc_params = {\"max_depth\": [6], \"class_weight\": [\"balanced\"]}\n",
    "#gb_params = {\"max_depth\": [3, 9], \"n_estimators\": [100, 300], \"learning_rate\": [0.1, 0.01]}\n",
    "#xgboost_params = {\"max_depth\": [6, 9], \"learning_rate\": [0.3, 0.03]}\n",
    "#hbg_params = {\"max_depth\": [6, 9], \"learning_rate\": [0.1, 0.01], \"max_iter\":[100, 200], \"class_weight\":[None, \"balanced\"]}\n",
    "catboost_params = {'iterations': [1000], 'depth':[6], 'boosting_type': ['Ordered'], \"auto_class_weights\": [\"SqrtBalanced\"], \"loss_function\": [\"MultiClassOneVsAll\"]} #\"l2_leaf_reg\":[4] # }\n",
    "nn_params = {'hidden_layer_sizes': [(25, 8)], \"learning_rate_init\": [0.01]}\n",
    "#svc_params = {\"C\": [1, 0.1], \"class_weight\": [None, \"balanced\"]}\n",
    "\n",
    "\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42), log_reg_params),\n",
    "    (\"NB\", GaussianNB(), nb_params), # ele ajusta automaticamente the class priors as a parameter\n",
    "    #(\"KNNC\", KNeighborsClassifier(), knn_params),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42), rfc_params),\n",
    "    #(\"Gradient Boosting\", GradientBoostingClassifier(random_state=42), gb_params),\n",
    "    #(\"HGB\", HistGradientBoostingClassifier(random_state=42), hbg_params),\n",
    "    #(\"xgboost\", XGBClassifier(random_state=42, verbose=0), xgboost_params),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=100), catboost_params),\n",
    "    (\"Neural Network\", MLPClassifier(random_state=42, verbose=10), nn_params),\n",
    "    #(\"SVC\", SVC(random_state=42), svc_params),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV_1/3 for ['Claim Injury Type_encoded']...\n",
      "Ordinal encoding...\n",
      "Frequency encoding...\n",
      "Impuiting missing values...\n",
      "Testing combinations for Logistic Regression...\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': None}\n",
      "Train F1-score: 0.414\n",
      "Thresholds: [np.float64(0.30222754508182975), np.float64(0.43695368769717763), np.float64(0.12450631621498295), np.float64(0.38939472874069364), np.float64(0.2957329241962443), np.float64(0.06675727049958108), np.float64(0.056719415102136864), np.float64(0.2358520836305238)]\n",
      "Validation F1-score: 0.412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.44      0.52      4159\n",
      "         1.0       0.87      0.92      0.89     97031\n",
      "         2.0       0.25      0.29      0.27     22970\n",
      "         3.0       0.72      0.65      0.68     49505\n",
      "         4.0       0.57      0.47      0.52     16094\n",
      "         5.0       0.12      0.11      0.12      1403\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.56      0.20      0.30       157\n",
      "\n",
      "    accuracy                           0.72    191351\n",
      "   macro avg       0.46      0.39      0.41    191351\n",
      "weighted avg       0.72      0.72      0.72    191351\n",
      "\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.376\n",
      "Thresholds: [np.float64(0.9083336809338403), np.float64(0.06413474761204827), np.float64(0.3124247784870084), np.float64(0.10812874379474016), np.float64(0.3158506154599192), np.float64(0.45631209267896833), np.float64(0.9123954978065522), np.float64(0.9891173281920222)]\n",
      "Validation F1-score: 0.376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.47      0.49      4159\n",
      "         1.0       0.84      0.97      0.90     97031\n",
      "         2.0       0.39      0.05      0.08     22970\n",
      "         3.0       0.69      0.79      0.74     49505\n",
      "         4.0       0.61      0.39      0.48     16094\n",
      "         5.0       0.10      0.23      0.14      1403\n",
      "         6.0       0.01      0.41      0.02        32\n",
      "         7.0       0.09      0.78      0.16       157\n",
      "\n",
      "    accuracy                           0.75    191351\n",
      "   macro avg       0.40      0.51      0.38    191351\n",
      "weighted avg       0.71      0.75      0.71    191351\n",
      "\n",
      "Best params for Logistic Regression:\n",
      "--------------------------------------------------\n",
      "Testing combinations for NB...\n",
      "NB...\n",
      "Params: {'var_smoothing': 1e-09}\n",
      "Train F1-score: 0.312\n",
      "Thresholds: [np.float64(0.9999658863299953), np.float64(2.7631930129536503e-14), np.float64(0.00014017634169377006), np.float64(5.511999872738702e-06), np.float64(0.0015386865344977458), np.float64(0.999611525259389), np.float64(0.0013868018852473258), np.float64(0.99999943959222)]\n",
      "Validation F1-score: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.15      0.21      4159\n",
      "         1.0       0.83      0.97      0.90     97031\n",
      "         2.0       0.42      0.02      0.03     22970\n",
      "         3.0       0.66      0.69      0.67     49505\n",
      "         4.0       0.49      0.38      0.43     16094\n",
      "         5.0       0.06      0.43      0.11      1403\n",
      "         6.0       0.01      0.06      0.02        32\n",
      "         7.0       0.06      0.60      0.11       157\n",
      "\n",
      "    accuracy                           0.71    191351\n",
      "   macro avg       0.36      0.41      0.31    191351\n",
      "weighted avg       0.69      0.71      0.67    191351\n",
      "\n",
      "NB...\n",
      "Params: {'var_smoothing': 0.1}\n",
      "Train F1-score: 0.345\n",
      "Thresholds: [np.float64(0.9998093384043387), np.float64(0.029333505003163438), np.float64(0.0021686511858112966), np.float64(0.03298391272697368), np.float64(0.36787088333071166), np.float64(0.24615759453103803), np.float64(0.622202266521301), np.float64(0.933912540437695)]\n",
      "Validation F1-score: 0.335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.56      0.47      4159\n",
      "         1.0       0.87      0.88      0.88     97031\n",
      "         2.0       0.19      0.41      0.26     22970\n",
      "         3.0       0.66      0.29      0.40     49505\n",
      "         4.0       0.49      0.36      0.41     16094\n",
      "         5.0       0.07      0.12      0.08      1403\n",
      "         6.0       0.02      0.06      0.03        32\n",
      "         7.0       0.13      0.16      0.14       157\n",
      "\n",
      "    accuracy                           0.62    191351\n",
      "   macro avg       0.35      0.35      0.33    191351\n",
      "weighted avg       0.68      0.62      0.62    191351\n",
      "\n",
      "Best params for NB:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Random Forest...\n",
      "Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.417\n",
      "Thresholds: [np.float64(0.7996846463087931), np.float64(0.18703778469649815), np.float64(0.10895401880426131), np.float64(0.1250680362409125), np.float64(0.2329257592543744), np.float64(0.4053412950532701), np.float64(0.5142248084645158), np.float64(0.6853835037776644)]\n",
      "Validation F1-score: 0.397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.54      0.56      4159\n",
      "         1.0       0.91      0.59      0.71     97031\n",
      "         2.0       0.19      0.45      0.27     22970\n",
      "         3.0       0.69      0.86      0.77     49505\n",
      "         4.0       0.72      0.38      0.50     16094\n",
      "         5.0       0.00      0.00      0.00      1403\n",
      "         6.0       0.02      0.09      0.03        32\n",
      "         7.0       0.22      0.66      0.33       157\n",
      "\n",
      "    accuracy                           0.62    191351\n",
      "   macro avg       0.42      0.45      0.40    191351\n",
      "weighted avg       0.74      0.62      0.65    191351\n",
      "\n",
      "OVR_Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.337\n",
      "Thresholds: [np.float64(0.5213914965105094), np.float64(0.20306282842638146), np.float64(0.27109466077608485), np.float64(0.20293961889794096), np.float64(0.24343834034030146), np.float64(0.2621346376134095), np.float64(0.20834975918655127), np.float64(0.2383564970852829)]\n",
      "Validation F1-score: 0.306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.02      0.04      4159\n",
      "         1.0       0.84      0.97      0.90     97031\n",
      "         2.0       0.52      0.04      0.08     22970\n",
      "         3.0       0.67      0.93      0.78     49505\n",
      "         4.0       0.76      0.35      0.47     16094\n",
      "         5.0       0.23      0.00      0.00      1403\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.09      0.58      0.16       157\n",
      "\n",
      "    accuracy                           0.77    191351\n",
      "   macro avg       0.50      0.36      0.31    191351\n",
      "weighted avg       0.75      0.77      0.71    191351\n",
      "\n",
      "Best params for Random Forest:\n",
      "--------------------------------------------------\n",
      "Testing combinations for CatBoost...\n",
      "0:\tlearn: 0.6714928\ttotal: 472ms\tremaining: 7m 51s\n",
      "10:\tlearn: 0.5101505\ttotal: 3.02s\tremaining: 4m 31s\n",
      "20:\tlearn: 0.4108891\ttotal: 5.64s\tremaining: 4m 22s\n",
      "30:\tlearn: 0.3458870\ttotal: 8.23s\tremaining: 4m 17s\n",
      "40:\tlearn: 0.3017644\ttotal: 10.9s\tremaining: 4m 14s\n",
      "50:\tlearn: 0.2712276\ttotal: 13.5s\tremaining: 4m 12s\n",
      "60:\tlearn: 0.2496251\ttotal: 16.2s\tremaining: 4m 9s\n",
      "70:\tlearn: 0.2338806\ttotal: 19.1s\tremaining: 4m 9s\n",
      "80:\tlearn: 0.2224057\ttotal: 22.2s\tremaining: 4m 11s\n",
      "90:\tlearn: 0.2138981\ttotal: 25.1s\tremaining: 4m 10s\n",
      "100:\tlearn: 0.2077012\ttotal: 27.9s\tremaining: 4m 8s\n",
      "110:\tlearn: 0.2026176\ttotal: 30.7s\tremaining: 4m 6s\n",
      "120:\tlearn: 0.1985827\ttotal: 33.5s\tremaining: 4m 3s\n",
      "130:\tlearn: 0.1953441\ttotal: 36.1s\tremaining: 3m 59s\n",
      "140:\tlearn: 0.1927385\ttotal: 38.8s\tremaining: 3m 56s\n",
      "150:\tlearn: 0.1904971\ttotal: 41.3s\tremaining: 3m 52s\n",
      "160:\tlearn: 0.1886317\ttotal: 44s\tremaining: 3m 49s\n",
      "170:\tlearn: 0.1869003\ttotal: 46.5s\tremaining: 3m 45s\n",
      "180:\tlearn: 0.1855557\ttotal: 49s\tremaining: 3m 41s\n",
      "190:\tlearn: 0.1842773\ttotal: 51.5s\tremaining: 3m 38s\n",
      "200:\tlearn: 0.1832900\ttotal: 54s\tremaining: 3m 34s\n",
      "210:\tlearn: 0.1822982\ttotal: 56.5s\tremaining: 3m 31s\n",
      "220:\tlearn: 0.1815761\ttotal: 59.1s\tremaining: 3m 28s\n",
      "230:\tlearn: 0.1806944\ttotal: 1m 1s\tremaining: 3m 25s\n",
      "240:\tlearn: 0.1798411\ttotal: 1m 4s\tremaining: 3m 22s\n",
      "250:\tlearn: 0.1792606\ttotal: 1m 6s\tremaining: 3m 19s\n",
      "260:\tlearn: 0.1786005\ttotal: 1m 9s\tremaining: 3m 15s\n",
      "270:\tlearn: 0.1779226\ttotal: 1m 11s\tremaining: 3m 13s\n",
      "280:\tlearn: 0.1774180\ttotal: 1m 14s\tremaining: 3m 10s\n",
      "290:\tlearn: 0.1769307\ttotal: 1m 16s\tremaining: 3m 7s\n",
      "300:\tlearn: 0.1764453\ttotal: 1m 19s\tremaining: 3m 4s\n",
      "310:\tlearn: 0.1760112\ttotal: 1m 22s\tremaining: 3m 1s\n",
      "320:\tlearn: 0.1755489\ttotal: 1m 24s\tremaining: 2m 59s\n",
      "330:\tlearn: 0.1750826\ttotal: 1m 27s\tremaining: 2m 56s\n",
      "340:\tlearn: 0.1747154\ttotal: 1m 29s\tremaining: 2m 53s\n",
      "350:\tlearn: 0.1744119\ttotal: 1m 32s\tremaining: 2m 50s\n",
      "360:\tlearn: 0.1740236\ttotal: 1m 34s\tremaining: 2m 47s\n",
      "370:\tlearn: 0.1736622\ttotal: 1m 37s\tremaining: 2m 45s\n",
      "380:\tlearn: 0.1733563\ttotal: 1m 39s\tremaining: 2m 42s\n",
      "390:\tlearn: 0.1730404\ttotal: 1m 42s\tremaining: 2m 39s\n",
      "400:\tlearn: 0.1727603\ttotal: 1m 45s\tremaining: 2m 36s\n",
      "410:\tlearn: 0.1724871\ttotal: 1m 47s\tremaining: 2m 34s\n",
      "420:\tlearn: 0.1722420\ttotal: 1m 50s\tremaining: 2m 31s\n",
      "430:\tlearn: 0.1719327\ttotal: 1m 52s\tremaining: 2m 28s\n",
      "440:\tlearn: 0.1716858\ttotal: 1m 55s\tremaining: 2m 26s\n",
      "450:\tlearn: 0.1714316\ttotal: 1m 58s\tremaining: 2m 23s\n",
      "460:\tlearn: 0.1712014\ttotal: 2m\tremaining: 2m 20s\n",
      "470:\tlearn: 0.1709405\ttotal: 2m 3s\tremaining: 2m 18s\n",
      "480:\tlearn: 0.1706509\ttotal: 2m 5s\tremaining: 2m 15s\n",
      "490:\tlearn: 0.1703652\ttotal: 2m 8s\tremaining: 2m 12s\n",
      "500:\tlearn: 0.1701391\ttotal: 2m 10s\tremaining: 2m 10s\n",
      "510:\tlearn: 0.1699164\ttotal: 2m 13s\tremaining: 2m 7s\n",
      "520:\tlearn: 0.1697325\ttotal: 2m 15s\tremaining: 2m 4s\n",
      "530:\tlearn: 0.1694953\ttotal: 2m 18s\tremaining: 2m 2s\n",
      "540:\tlearn: 0.1693015\ttotal: 2m 20s\tremaining: 1m 59s\n",
      "550:\tlearn: 0.1690453\ttotal: 2m 23s\tremaining: 1m 57s\n",
      "560:\tlearn: 0.1688530\ttotal: 2m 26s\tremaining: 1m 54s\n",
      "570:\tlearn: 0.1686821\ttotal: 2m 28s\tremaining: 1m 51s\n",
      "580:\tlearn: 0.1684861\ttotal: 2m 31s\tremaining: 1m 49s\n",
      "590:\tlearn: 0.1683274\ttotal: 2m 34s\tremaining: 1m 46s\n",
      "600:\tlearn: 0.1681065\ttotal: 2m 36s\tremaining: 1m 44s\n",
      "610:\tlearn: 0.1679053\ttotal: 2m 39s\tremaining: 1m 41s\n",
      "620:\tlearn: 0.1677341\ttotal: 2m 42s\tremaining: 1m 39s\n",
      "630:\tlearn: 0.1676017\ttotal: 2m 45s\tremaining: 1m 36s\n",
      "640:\tlearn: 0.1674390\ttotal: 2m 47s\tremaining: 1m 34s\n",
      "650:\tlearn: 0.1672912\ttotal: 2m 50s\tremaining: 1m 31s\n",
      "660:\tlearn: 0.1671892\ttotal: 2m 53s\tremaining: 1m 28s\n",
      "670:\tlearn: 0.1670267\ttotal: 2m 56s\tremaining: 1m 26s\n",
      "680:\tlearn: 0.1668576\ttotal: 2m 58s\tremaining: 1m 23s\n",
      "690:\tlearn: 0.1667194\ttotal: 3m 1s\tremaining: 1m 21s\n",
      "700:\tlearn: 0.1665567\ttotal: 3m 3s\tremaining: 1m 18s\n",
      "710:\tlearn: 0.1664084\ttotal: 3m 6s\tremaining: 1m 15s\n",
      "720:\tlearn: 0.1662635\ttotal: 3m 8s\tremaining: 1m 13s\n",
      "730:\tlearn: 0.1661131\ttotal: 3m 11s\tremaining: 1m 10s\n",
      "740:\tlearn: 0.1659887\ttotal: 3m 14s\tremaining: 1m 7s\n",
      "750:\tlearn: 0.1658773\ttotal: 3m 16s\tremaining: 1m 5s\n",
      "760:\tlearn: 0.1657398\ttotal: 3m 19s\tremaining: 1m 2s\n",
      "770:\tlearn: 0.1656219\ttotal: 3m 21s\tremaining: 60s\n",
      "780:\tlearn: 0.1654869\ttotal: 3m 24s\tremaining: 57.4s\n",
      "790:\tlearn: 0.1653804\ttotal: 3m 27s\tremaining: 54.7s\n",
      "800:\tlearn: 0.1652604\ttotal: 3m 29s\tremaining: 52.1s\n",
      "810:\tlearn: 0.1651391\ttotal: 3m 32s\tremaining: 49.5s\n",
      "820:\tlearn: 0.1650297\ttotal: 3m 34s\tremaining: 46.8s\n",
      "830:\tlearn: 0.1648954\ttotal: 3m 37s\tremaining: 44.2s\n",
      "840:\tlearn: 0.1647789\ttotal: 3m 39s\tremaining: 41.6s\n",
      "850:\tlearn: 0.1646602\ttotal: 3m 42s\tremaining: 39s\n",
      "860:\tlearn: 0.1645585\ttotal: 3m 45s\tremaining: 36.3s\n",
      "870:\tlearn: 0.1644145\ttotal: 3m 47s\tremaining: 33.7s\n",
      "880:\tlearn: 0.1643321\ttotal: 3m 50s\tremaining: 31.1s\n",
      "890:\tlearn: 0.1642582\ttotal: 3m 52s\tremaining: 28.5s\n",
      "900:\tlearn: 0.1640954\ttotal: 3m 55s\tremaining: 25.9s\n",
      "910:\tlearn: 0.1639715\ttotal: 3m 58s\tremaining: 23.3s\n",
      "920:\tlearn: 0.1638701\ttotal: 4m 1s\tremaining: 20.7s\n",
      "930:\tlearn: 0.1637872\ttotal: 4m 4s\tremaining: 18.1s\n",
      "940:\tlearn: 0.1636783\ttotal: 4m 6s\tremaining: 15.5s\n",
      "950:\tlearn: 0.1635882\ttotal: 4m 9s\tremaining: 12.9s\n",
      "960:\tlearn: 0.1634599\ttotal: 4m 12s\tremaining: 10.2s\n",
      "970:\tlearn: 0.1633580\ttotal: 4m 15s\tremaining: 7.63s\n",
      "980:\tlearn: 0.1632818\ttotal: 4m 18s\tremaining: 5s\n",
      "990:\tlearn: 0.1631783\ttotal: 4m 21s\tremaining: 2.37s\n",
      "999:\tlearn: 0.1630981\ttotal: 4m 23s\tremaining: 0us\n",
      "CatBoost...\n",
      "Params: {'iterations': 1000, 'depth': 6, 'boosting_type': 'Ordered', 'auto_class_weights': 'SqrtBalanced', 'loss_function': 'MultiClassOneVsAll'}\n",
      "Train F1-score: 0.576\n",
      "Thresholds: [np.float64(0.5572894301903449), np.float64(0.289656214694875), np.float64(0.2499224178981729), np.float64(0.26935322055793304), np.float64(0.38824627215237056), np.float64(0.31034064575501397), np.float64(0.3511731250491418), np.float64(0.6637296486026388)]\n",
      "Validation F1-score: 0.482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.56      0.60      4159\n",
      "         1.0       0.87      0.95      0.91     97031\n",
      "         2.0       0.42      0.18      0.25     22970\n",
      "         3.0       0.75      0.83      0.79     49505\n",
      "         4.0       0.68      0.64      0.66     16094\n",
      "         5.0       0.20      0.16      0.18      1403\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.42      0.55      0.47       157\n",
      "\n",
      "    accuracy                           0.79    191351\n",
      "   macro avg       0.50      0.48      0.48    191351\n",
      "weighted avg       0.76      0.79      0.76    191351\n",
      "\n",
      "Best params for CatBoost:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Neural Network...\n",
      "Iteration 1, loss = 0.64749844\n",
      "Iteration 2, loss = 0.61553101\n",
      "Iteration 3, loss = 0.60958599\n",
      "Iteration 4, loss = 0.60552055\n",
      "Iteration 5, loss = 0.60244808\n",
      "Iteration 6, loss = 0.60091382\n",
      "Iteration 7, loss = 0.59844044\n",
      "Iteration 8, loss = 0.59715847\n",
      "Iteration 9, loss = 0.59634145\n",
      "Iteration 10, loss = 0.59536508\n",
      "Iteration 11, loss = 0.59494227\n",
      "Iteration 12, loss = 0.59430251\n",
      "Iteration 13, loss = 0.59387088\n",
      "Iteration 14, loss = 0.59360664\n",
      "Iteration 15, loss = 0.59333809\n",
      "Iteration 16, loss = 0.59329971\n",
      "Iteration 17, loss = 0.59328480\n",
      "Iteration 18, loss = 0.59267429\n",
      "Iteration 19, loss = 0.59231258\n",
      "Iteration 20, loss = 0.59222379\n",
      "Iteration 21, loss = 0.59232802\n",
      "Iteration 22, loss = 0.59222084\n",
      "Iteration 23, loss = 0.59244190\n",
      "Iteration 24, loss = 0.59204885\n",
      "Iteration 25, loss = 0.59210614\n",
      "Iteration 26, loss = 0.59168764\n",
      "Iteration 27, loss = 0.59221240\n",
      "Iteration 28, loss = 0.59235228\n",
      "Iteration 29, loss = 0.59149766\n",
      "Iteration 30, loss = 0.59179768\n",
      "Iteration 31, loss = 0.59184732\n",
      "Iteration 32, loss = 0.59137766\n",
      "Iteration 33, loss = 0.59171739\n",
      "Iteration 34, loss = 0.59150180\n",
      "Iteration 35, loss = 0.59160492\n",
      "Iteration 36, loss = 0.59152918\n",
      "Iteration 37, loss = 0.59162180\n",
      "Iteration 38, loss = 0.59166585\n",
      "Iteration 39, loss = 0.59122065\n",
      "Iteration 40, loss = 0.59114499\n",
      "Iteration 41, loss = 0.59142682\n",
      "Iteration 42, loss = 0.59103385\n",
      "Iteration 43, loss = 0.59118643\n",
      "Iteration 44, loss = 0.59075190\n",
      "Iteration 45, loss = 0.59103260\n",
      "Iteration 46, loss = 0.59109233\n",
      "Iteration 47, loss = 0.59108249\n",
      "Iteration 48, loss = 0.59134666\n",
      "Iteration 49, loss = 0.59111131\n",
      "Iteration 50, loss = 0.59089441\n",
      "Iteration 51, loss = 0.59110934\n",
      "Iteration 52, loss = 0.59113193\n",
      "Iteration 53, loss = 0.59109831\n",
      "Iteration 54, loss = 0.59113391\n",
      "Iteration 55, loss = 0.59117327\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Neural Network...\n",
      "Params: {'hidden_layer_sizes': (25, 8), 'learning_rate_init': 0.01}\n",
      "Train F1-score: 0.462\n",
      "Thresholds: [np.float64(0.41097442593260813), np.float64(0.44405894922979133), np.float64(0.1765630152641987), np.float64(0.3939704566327855), np.float64(0.31404791242317864), np.float64(0.12091173345667594), np.float64(0.002783862000215567), np.float64(0.11941474344298779)]\n",
      "Validation F1-score: 0.454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.47      0.55      4159\n",
      "         1.0       0.87      0.92      0.90     97031\n",
      "         2.0       0.34      0.24      0.28     22970\n",
      "         3.0       0.75      0.79      0.77     49505\n",
      "         4.0       0.64      0.61      0.62     16094\n",
      "         5.0       0.16      0.13      0.14      1403\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.35      0.39      0.37       157\n",
      "\n",
      "    accuracy                           0.76    191351\n",
      "   macro avg       0.47      0.45      0.45    191351\n",
      "weighted avg       0.74      0.76      0.75    191351\n",
      "\n",
      "Best params for Neural Network:\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Starting CV_2/3 for ['Claim Injury Type_encoded']...\n",
      "Ordinal encoding...\n",
      "Frequency encoding...\n",
      "Impuiting missing values...\n",
      "Testing combinations for Logistic Regression...\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': None}\n",
      "Train F1-score: 0.429\n",
      "Thresholds: [np.float64(0.28157287990822416), np.float64(0.4395171962638743), np.float64(0.1205549889112178), np.float64(0.4107971413250773), np.float64(0.28008603382016023), np.float64(0.07505427270728371), np.float64(0.051957838765079575), np.float64(0.1109860103630645)]\n",
      "Validation F1-score: 0.416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.44      0.51      4159\n",
      "         1.0       0.87      0.91      0.89     97031\n",
      "         2.0       0.24      0.32      0.28     22970\n",
      "         3.0       0.73      0.59      0.65     49505\n",
      "         4.0       0.55      0.51      0.53     16093\n",
      "         5.0       0.13      0.09      0.11      1404\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.35      0.36      0.36       157\n",
      "\n",
      "    accuracy                           0.71    191351\n",
      "   macro avg       0.44      0.40      0.42    191351\n",
      "weighted avg       0.72      0.71      0.71    191351\n",
      "\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.376\n",
      "Thresholds: [np.float64(0.8903555375875856), np.float64(0.06138164160157029), np.float64(0.30367293697774517), np.float64(0.11008464400540302), np.float64(0.3022255206314609), np.float64(0.515617055358116), np.float64(0.9850130153302276), np.float64(0.9757690085203957)]\n",
      "Validation F1-score: 0.375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.44      0.48      4159\n",
      "         1.0       0.84      0.97      0.90     97031\n",
      "         2.0       0.39      0.05      0.08     22970\n",
      "         3.0       0.70      0.80      0.74     49505\n",
      "         4.0       0.59      0.42      0.49     16093\n",
      "         5.0       0.10      0.14      0.12      1404\n",
      "         6.0       0.01      0.34      0.01        32\n",
      "         7.0       0.10      0.83      0.17       157\n",
      "\n",
      "    accuracy                           0.75    191351\n",
      "   macro avg       0.40      0.50      0.38    191351\n",
      "weighted avg       0.71      0.75      0.71    191351\n",
      "\n",
      "Best params for Logistic Regression:\n",
      "--------------------------------------------------\n",
      "Testing combinations for NB...\n",
      "NB...\n",
      "Params: {'var_smoothing': 1e-09}\n",
      "Train F1-score: 0.311\n",
      "Thresholds: [np.float64(0.999845012218019), np.float64(1.716008550188906e-14), np.float64(7.681559109994461e-05), np.float64(4.403770500332599e-06), np.float64(0.0004732918713624933), np.float64(0.9997702104227294), np.float64(0.3416179969593005), np.float64(0.9999995263379537)]\n",
      "Validation F1-score: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.14      0.20      4159\n",
      "         1.0       0.83      0.97      0.90     97031\n",
      "         2.0       0.43      0.02      0.05     22970\n",
      "         3.0       0.67      0.64      0.66     49505\n",
      "         4.0       0.43      0.53      0.47     16093\n",
      "         5.0       0.07      0.35      0.12      1404\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.05      0.61      0.09       157\n",
      "\n",
      "    accuracy                           0.71    191351\n",
      "   macro avg       0.36      0.41      0.31    191351\n",
      "weighted avg       0.69      0.71      0.67    191351\n",
      "\n",
      "NB...\n",
      "Params: {'var_smoothing': 0.1}\n",
      "Train F1-score: 0.338\n",
      "Thresholds: [np.float64(0.9943855252633115), np.float64(0.011977499014128232), np.float64(0.002348046300187804), np.float64(0.027187124794343872), np.float64(0.3501506813984116), np.float64(0.27904903510948764), np.float64(0.9182256161942062), np.float64(0.9628647063226976)]\n",
      "Validation F1-score: 0.338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.56      0.48      4159\n",
      "         1.0       0.86      0.89      0.88     97031\n",
      "         2.0       0.19      0.40      0.26     22970\n",
      "         3.0       0.65      0.31      0.42     49505\n",
      "         4.0       0.51      0.36      0.42     16093\n",
      "         5.0       0.07      0.12      0.09      1404\n",
      "         6.0       0.01      0.03      0.01        32\n",
      "         7.0       0.12      0.18      0.15       157\n",
      "\n",
      "    accuracy                           0.62    191351\n",
      "   macro avg       0.35      0.36      0.34    191351\n",
      "weighted avg       0.68      0.62      0.63    191351\n",
      "\n",
      "Best params for NB:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Random Forest...\n",
      "Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.419\n",
      "Thresholds: [np.float64(0.818214122711663), np.float64(0.17283636010394304), np.float64(0.10615916177198707), np.float64(0.12834441865569524), np.float64(0.2530135044333097), np.float64(0.37805617134979025), np.float64(0.4385997869625561), np.float64(0.6033015043177007)]\n",
      "Validation F1-score: 0.408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.53      0.57      4159\n",
      "         1.0       0.90      0.72      0.80     97031\n",
      "         2.0       0.21      0.37      0.27     22970\n",
      "         3.0       0.68      0.87      0.77     49505\n",
      "         4.0       0.77      0.34      0.47     16093\n",
      "         5.0       0.27      0.01      0.02      1404\n",
      "         6.0       0.02      0.19      0.03        32\n",
      "         7.0       0.21      0.76      0.33       157\n",
      "\n",
      "    accuracy                           0.67    191351\n",
      "   macro avg       0.46      0.47      0.41    191351\n",
      "weighted avg       0.74      0.67      0.69    191351\n",
      "\n",
      "OVR_Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.336\n",
      "Thresholds: [np.float64(0.5198951495295187), np.float64(0.20615610503263318), np.float64(0.24962973714681852), np.float64(0.20619823572970597), np.float64(0.23898425699548087), np.float64(0.2637013198224009), np.float64(0.22999384023700853), np.float64(0.2568632888825332)]\n",
      "Validation F1-score: 0.315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.02      0.05      4159\n",
      "         1.0       0.85      0.97      0.90     97031\n",
      "         2.0       0.47      0.06      0.11     22970\n",
      "         3.0       0.67      0.93      0.78     49505\n",
      "         4.0       0.74      0.39      0.51     16093\n",
      "         5.0       0.11      0.00      0.00      1404\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.10      0.42      0.16       157\n",
      "\n",
      "    accuracy                           0.77    191351\n",
      "   macro avg       0.48      0.35      0.31    191351\n",
      "weighted avg       0.74      0.77      0.72    191351\n",
      "\n",
      "Best params for Random Forest:\n",
      "--------------------------------------------------\n",
      "Testing combinations for CatBoost...\n",
      "0:\tlearn: 0.6714911\ttotal: 345ms\tremaining: 5m 45s\n",
      "10:\tlearn: 0.5103591\ttotal: 2.88s\tremaining: 4m 19s\n",
      "20:\tlearn: 0.4108731\ttotal: 5.48s\tremaining: 4m 15s\n",
      "30:\tlearn: 0.3457106\ttotal: 8.01s\tremaining: 4m 10s\n",
      "40:\tlearn: 0.3016368\ttotal: 10.5s\tremaining: 4m 6s\n",
      "50:\tlearn: 0.2711801\ttotal: 13.1s\tremaining: 4m 3s\n",
      "60:\tlearn: 0.2493253\ttotal: 15.7s\tremaining: 4m\n",
      "70:\tlearn: 0.2336468\ttotal: 18.2s\tremaining: 3m 58s\n",
      "80:\tlearn: 0.2223228\ttotal: 20.9s\tremaining: 3m 56s\n",
      "90:\tlearn: 0.2137453\ttotal: 23.5s\tremaining: 3m 54s\n",
      "100:\tlearn: 0.2075670\ttotal: 26.1s\tremaining: 3m 52s\n",
      "110:\tlearn: 0.2024545\ttotal: 28.7s\tremaining: 3m 49s\n",
      "120:\tlearn: 0.1983719\ttotal: 31.4s\tremaining: 3m 48s\n",
      "130:\tlearn: 0.1953281\ttotal: 34.1s\tremaining: 3m 46s\n",
      "140:\tlearn: 0.1929484\ttotal: 37.1s\tremaining: 3m 45s\n",
      "150:\tlearn: 0.1907108\ttotal: 39.9s\tremaining: 3m 44s\n",
      "160:\tlearn: 0.1886779\ttotal: 43s\tremaining: 3m 44s\n",
      "170:\tlearn: 0.1869358\ttotal: 46s\tremaining: 3m 43s\n",
      "180:\tlearn: 0.1854569\ttotal: 48.9s\tremaining: 3m 41s\n",
      "190:\tlearn: 0.1842421\ttotal: 51.7s\tremaining: 3m 39s\n",
      "200:\tlearn: 0.1831110\ttotal: 54.7s\tremaining: 3m 37s\n",
      "210:\tlearn: 0.1820998\ttotal: 57.6s\tremaining: 3m 35s\n",
      "220:\tlearn: 0.1812235\ttotal: 1m\tremaining: 3m 33s\n",
      "230:\tlearn: 0.1804373\ttotal: 1m 3s\tremaining: 3m 31s\n",
      "240:\tlearn: 0.1797062\ttotal: 1m 6s\tremaining: 3m 29s\n",
      "250:\tlearn: 0.1790718\ttotal: 1m 9s\tremaining: 3m 26s\n",
      "260:\tlearn: 0.1785119\ttotal: 1m 12s\tremaining: 3m 24s\n",
      "270:\tlearn: 0.1779095\ttotal: 1m 14s\tremaining: 3m 21s\n",
      "280:\tlearn: 0.1774232\ttotal: 1m 17s\tremaining: 3m 18s\n",
      "290:\tlearn: 0.1768806\ttotal: 1m 20s\tremaining: 3m 15s\n",
      "300:\tlearn: 0.1764358\ttotal: 1m 23s\tremaining: 3m 13s\n",
      "310:\tlearn: 0.1760267\ttotal: 1m 26s\tremaining: 3m 10s\n",
      "320:\tlearn: 0.1755411\ttotal: 1m 28s\tremaining: 3m 7s\n",
      "330:\tlearn: 0.1750815\ttotal: 1m 31s\tremaining: 3m 4s\n",
      "340:\tlearn: 0.1747504\ttotal: 1m 34s\tremaining: 3m 1s\n",
      "350:\tlearn: 0.1744324\ttotal: 1m 36s\tremaining: 2m 58s\n",
      "360:\tlearn: 0.1741012\ttotal: 1m 39s\tremaining: 2m 55s\n",
      "370:\tlearn: 0.1737685\ttotal: 1m 41s\tremaining: 2m 52s\n",
      "380:\tlearn: 0.1734566\ttotal: 1m 44s\tremaining: 2m 49s\n",
      "390:\tlearn: 0.1731575\ttotal: 1m 46s\tremaining: 2m 46s\n",
      "400:\tlearn: 0.1728536\ttotal: 1m 49s\tremaining: 2m 43s\n",
      "410:\tlearn: 0.1725716\ttotal: 1m 51s\tremaining: 2m 40s\n",
      "420:\tlearn: 0.1722742\ttotal: 1m 54s\tremaining: 2m 37s\n",
      "430:\tlearn: 0.1720060\ttotal: 1m 57s\tremaining: 2m 34s\n",
      "440:\tlearn: 0.1717581\ttotal: 1m 59s\tremaining: 2m 31s\n",
      "450:\tlearn: 0.1714804\ttotal: 2m 2s\tremaining: 2m 29s\n",
      "460:\tlearn: 0.1712568\ttotal: 2m 5s\tremaining: 2m 26s\n",
      "470:\tlearn: 0.1710456\ttotal: 2m 8s\tremaining: 2m 23s\n",
      "480:\tlearn: 0.1707480\ttotal: 2m 10s\tremaining: 2m 21s\n",
      "490:\tlearn: 0.1704820\ttotal: 2m 13s\tremaining: 2m 18s\n",
      "500:\tlearn: 0.1702939\ttotal: 2m 16s\tremaining: 2m 15s\n",
      "510:\tlearn: 0.1700866\ttotal: 2m 18s\tremaining: 2m 12s\n",
      "520:\tlearn: 0.1698049\ttotal: 2m 21s\tremaining: 2m 10s\n",
      "530:\tlearn: 0.1695763\ttotal: 2m 24s\tremaining: 2m 7s\n",
      "540:\tlearn: 0.1693804\ttotal: 2m 26s\tremaining: 2m 4s\n",
      "550:\tlearn: 0.1691260\ttotal: 2m 29s\tremaining: 2m 2s\n",
      "560:\tlearn: 0.1689017\ttotal: 2m 32s\tremaining: 1m 59s\n",
      "570:\tlearn: 0.1687261\ttotal: 2m 35s\tremaining: 1m 56s\n",
      "580:\tlearn: 0.1685588\ttotal: 2m 38s\tremaining: 1m 53s\n",
      "590:\tlearn: 0.1683700\ttotal: 2m 40s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.1681784\ttotal: 2m 43s\tremaining: 1m 48s\n",
      "610:\tlearn: 0.1680351\ttotal: 2m 46s\tremaining: 1m 46s\n",
      "620:\tlearn: 0.1678789\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "630:\tlearn: 0.1677135\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "640:\tlearn: 0.1675312\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "650:\tlearn: 0.1673660\ttotal: 2m 57s\tremaining: 1m 35s\n",
      "660:\tlearn: 0.1671786\ttotal: 3m\tremaining: 1m 32s\n",
      "670:\tlearn: 0.1669885\ttotal: 3m 3s\tremaining: 1m 29s\n",
      "680:\tlearn: 0.1668473\ttotal: 3m 5s\tremaining: 1m 27s\n",
      "690:\tlearn: 0.1667274\ttotal: 3m 8s\tremaining: 1m 24s\n",
      "700:\tlearn: 0.1665971\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "710:\tlearn: 0.1664389\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "720:\tlearn: 0.1662935\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "730:\tlearn: 0.1661457\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "740:\tlearn: 0.1660175\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "750:\tlearn: 0.1659067\ttotal: 3m 23s\tremaining: 1m 7s\n",
      "760:\tlearn: 0.1657877\ttotal: 3m 26s\tremaining: 1m 4s\n",
      "770:\tlearn: 0.1656446\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "780:\tlearn: 0.1655069\ttotal: 3m 31s\tremaining: 59.4s\n",
      "790:\tlearn: 0.1653881\ttotal: 3m 34s\tremaining: 56.6s\n",
      "800:\tlearn: 0.1652721\ttotal: 3m 36s\tremaining: 53.9s\n",
      "810:\tlearn: 0.1651520\ttotal: 3m 39s\tremaining: 51.1s\n",
      "820:\tlearn: 0.1650350\ttotal: 3m 41s\tremaining: 48.4s\n",
      "830:\tlearn: 0.1649150\ttotal: 3m 44s\tremaining: 45.7s\n",
      "840:\tlearn: 0.1648116\ttotal: 3m 46s\tremaining: 42.9s\n",
      "850:\tlearn: 0.1647159\ttotal: 3m 49s\tremaining: 40.2s\n",
      "860:\tlearn: 0.1646291\ttotal: 3m 52s\tremaining: 37.5s\n",
      "870:\tlearn: 0.1645245\ttotal: 3m 54s\tremaining: 34.7s\n",
      "880:\tlearn: 0.1644249\ttotal: 3m 57s\tremaining: 32s\n",
      "890:\tlearn: 0.1642905\ttotal: 3m 59s\tremaining: 29.3s\n",
      "900:\tlearn: 0.1642293\ttotal: 4m 2s\tremaining: 26.6s\n",
      "910:\tlearn: 0.1641161\ttotal: 4m 4s\tremaining: 23.9s\n",
      "920:\tlearn: 0.1640164\ttotal: 4m 7s\tremaining: 21.2s\n",
      "930:\tlearn: 0.1639262\ttotal: 4m 9s\tremaining: 18.5s\n",
      "940:\tlearn: 0.1638341\ttotal: 4m 12s\tremaining: 15.8s\n",
      "950:\tlearn: 0.1637328\ttotal: 4m 15s\tremaining: 13.1s\n",
      "960:\tlearn: 0.1636355\ttotal: 4m 17s\tremaining: 10.5s\n",
      "970:\tlearn: 0.1635549\ttotal: 4m 20s\tremaining: 7.77s\n",
      "980:\tlearn: 0.1634662\ttotal: 4m 22s\tremaining: 5.09s\n",
      "990:\tlearn: 0.1633846\ttotal: 4m 25s\tremaining: 2.41s\n",
      "999:\tlearn: 0.1632774\ttotal: 4m 27s\tremaining: 0us\n",
      "CatBoost...\n",
      "Params: {'iterations': 1000, 'depth': 6, 'boosting_type': 'Ordered', 'auto_class_weights': 'SqrtBalanced', 'loss_function': 'MultiClassOneVsAll'}\n",
      "Train F1-score: 0.557\n",
      "Thresholds: [np.float64(0.5289787200860959), np.float64(0.2788996828563534), np.float64(0.2514684724823396), np.float64(0.27604406568558726), np.float64(0.3780499932753168), np.float64(0.381755828662105), np.float64(0.24882183254123047), np.float64(0.7622620979771334)]\n",
      "Validation F1-score: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.55      0.59      4159\n",
      "         1.0       0.87      0.95      0.91     97031\n",
      "         2.0       0.42      0.17      0.24     22970\n",
      "         3.0       0.75      0.84      0.79     49505\n",
      "         4.0       0.67      0.65      0.66     16093\n",
      "         5.0       0.30      0.11      0.16      1404\n",
      "         6.0       0.02      0.03      0.03        32\n",
      "         7.0       0.40      0.52      0.46       157\n",
      "\n",
      "    accuracy                           0.79    191351\n",
      "   macro avg       0.51      0.48      0.48    191351\n",
      "weighted avg       0.76      0.79      0.76    191351\n",
      "\n",
      "Best params for CatBoost:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Neural Network...\n",
      "Iteration 1, loss = 0.65097608\n",
      "Iteration 2, loss = 0.61788914\n",
      "Iteration 3, loss = 0.61095833\n",
      "Iteration 4, loss = 0.60601995\n",
      "Iteration 5, loss = 0.60316332\n",
      "Iteration 6, loss = 0.60103554\n",
      "Iteration 7, loss = 0.59976905\n",
      "Iteration 8, loss = 0.59912309\n",
      "Iteration 9, loss = 0.59807604\n",
      "Iteration 10, loss = 0.59686596\n",
      "Iteration 11, loss = 0.59721162\n",
      "Iteration 12, loss = 0.59719279\n",
      "Iteration 13, loss = 0.59633144\n",
      "Iteration 14, loss = 0.59620462\n",
      "Iteration 15, loss = 0.59486768\n",
      "Iteration 16, loss = 0.59518924\n",
      "Iteration 17, loss = 0.59468992\n",
      "Iteration 18, loss = 0.59493766\n",
      "Iteration 19, loss = 0.59401841\n",
      "Iteration 20, loss = 0.59466539\n",
      "Iteration 21, loss = 0.59391269\n",
      "Iteration 22, loss = 0.59417131\n",
      "Iteration 23, loss = 0.59350834\n",
      "Iteration 24, loss = 0.59340566\n",
      "Iteration 25, loss = 0.59342555\n",
      "Iteration 26, loss = 0.59359125\n",
      "Iteration 27, loss = 0.59267391\n",
      "Iteration 28, loss = 0.59298705\n",
      "Iteration 29, loss = 0.59325898\n",
      "Iteration 30, loss = 0.59342538\n",
      "Iteration 31, loss = 0.59334706\n",
      "Iteration 32, loss = 0.59269899\n",
      "Iteration 33, loss = 0.59276303\n",
      "Iteration 34, loss = 0.59322343\n",
      "Iteration 35, loss = 0.59284061\n",
      "Iteration 36, loss = 0.59269111\n",
      "Iteration 37, loss = 0.59305848\n",
      "Iteration 38, loss = 0.59284580\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Neural Network...\n",
      "Params: {'hidden_layer_sizes': (25, 8), 'learning_rate_init': 0.01}\n",
      "Train F1-score: 0.444\n",
      "Thresholds: [np.float64(0.2505585845891648), np.float64(0.43477005122651774), np.float64(0.19393787585153488), np.float64(0.34586949312372484), np.float64(0.3284476800426226), np.float64(0.09151493040616765), np.float64(0.00668071936880159), np.float64(0.09104861804868722)]\n",
      "Validation F1-score: 0.437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.46      0.54      4159\n",
      "         1.0       0.87      0.94      0.90     97031\n",
      "         2.0       0.33      0.25      0.28     22970\n",
      "         3.0       0.74      0.77      0.76     49505\n",
      "         4.0       0.65      0.60      0.62     16093\n",
      "         5.0       0.20      0.05      0.08      1404\n",
      "         6.0       0.00      0.00      0.00        32\n",
      "         7.0       0.42      0.25      0.31       157\n",
      "\n",
      "    accuracy                           0.76    191351\n",
      "   macro avg       0.49      0.41      0.44    191351\n",
      "weighted avg       0.74      0.76      0.75    191351\n",
      "\n",
      "Best params for Neural Network:\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Starting CV_3/3 for ['Claim Injury Type_encoded']...\n",
      "Ordinal encoding...\n",
      "Frequency encoding...\n",
      "Impuiting missing values...\n",
      "Testing combinations for Logistic Regression...\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': None}\n",
      "Train F1-score: 0.425\n",
      "Thresholds: [np.float64(0.31555740664154336), np.float64(0.45779154709047987), np.float64(0.13659487439637322), np.float64(0.39157856848743056), np.float64(0.3149028713971671), np.float64(0.06547121080105518), np.float64(0.13487043600772405), np.float64(0.136353192579985)]\n",
      "Validation F1-score: 0.424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.43      0.51      4159\n",
      "         1.0       0.87      0.92      0.89     97031\n",
      "         2.0       0.26      0.27      0.27     22970\n",
      "         3.0       0.72      0.68      0.70     49505\n",
      "         4.0       0.57      0.46      0.51     16093\n",
      "         5.0       0.12      0.13      0.12      1404\n",
      "         6.0       0.00      0.00      0.00        33\n",
      "         7.0       0.43      0.37      0.39       156\n",
      "\n",
      "    accuracy                           0.73    191351\n",
      "   macro avg       0.45      0.41      0.42    191351\n",
      "weighted avg       0.72      0.73      0.72    191351\n",
      "\n",
      "Logistic Regression...\n",
      "Params: {'C': 1, 'solver': 'lbfgs', 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.374\n",
      "Thresholds: [np.float64(0.8910407488725489), np.float64(0.05515821793951093), np.float64(0.2884629876883998), np.float64(0.10238823434623827), np.float64(0.31752077114587457), np.float64(0.4224626826179849), np.float64(0.9823060029337821), np.float64(0.9725033050473193)]\n",
      "Validation F1-score: 0.371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.42      0.47      4159\n",
      "         1.0       0.84      0.97      0.90     97031\n",
      "         2.0       0.41      0.05      0.08     22970\n",
      "         3.0       0.69      0.79      0.74     49505\n",
      "         4.0       0.61      0.38      0.46     16093\n",
      "         5.0       0.09      0.20      0.12      1404\n",
      "         6.0       0.01      0.42      0.02        33\n",
      "         7.0       0.09      0.79      0.17       156\n",
      "\n",
      "    accuracy                           0.75    191351\n",
      "   macro avg       0.41      0.50      0.37    191351\n",
      "weighted avg       0.72      0.75      0.71    191351\n",
      "\n",
      "Best params for Logistic Regression:\n",
      "--------------------------------------------------\n",
      "Testing combinations for NB...\n",
      "NB...\n",
      "Params: {'var_smoothing': 1e-09}\n",
      "Train F1-score: 0.281\n",
      "Thresholds: [np.float64(0.9989936988295304), np.float64(1.1219168988981623e-14), np.float64(0.00013296261600049912), np.float64(5.6724359696111474e-06), np.float64(2.513335596169109e-06), np.float64(0.0007707467130567101), np.float64(0.9999991039273581), np.float64(0.9999995917716421)]\n",
      "Validation F1-score: 0.276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.14      0.19      4159\n",
      "         1.0       0.83      0.97      0.90     97031\n",
      "         2.0       0.41      0.01      0.02     22970\n",
      "         3.0       0.74      0.35      0.48     49505\n",
      "         4.0       0.40      0.55      0.46     16093\n",
      "         5.0       0.04      0.75      0.08      1404\n",
      "         6.0       0.00      0.39      0.01        33\n",
      "         7.0       0.04      0.42      0.07       156\n",
      "\n",
      "    accuracy                           0.64    191351\n",
      "   macro avg       0.35      0.45      0.28    191351\n",
      "weighted avg       0.70      0.64      0.62    191351\n",
      "\n",
      "NB...\n",
      "Params: {'var_smoothing': 0.1}\n",
      "Train F1-score: 0.342\n",
      "Thresholds: [np.float64(0.9991802613177988), np.float64(0.026590456178735296), np.float64(0.0017271147043748096), np.float64(0.029452297103572087), np.float64(0.46262212179885726), np.float64(0.23931112863873774), np.float64(0.9874520671714065), np.float64(0.9666489823049582)]\n",
      "Validation F1-score: 0.335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.55      0.47      4159\n",
      "         1.0       0.87      0.88      0.87     97031\n",
      "         2.0       0.19      0.43      0.26     22970\n",
      "         3.0       0.66      0.29      0.41     49505\n",
      "         4.0       0.53      0.33      0.41     16093\n",
      "         5.0       0.07      0.14      0.09      1404\n",
      "         6.0       0.03      0.06      0.04        33\n",
      "         7.0       0.12      0.16      0.14       156\n",
      "\n",
      "    accuracy                           0.61    191351\n",
      "   macro avg       0.36      0.36      0.34    191351\n",
      "weighted avg       0.69      0.61      0.63    191351\n",
      "\n",
      "Best params for NB:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Random Forest...\n",
      "Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.445\n",
      "Thresholds: [np.float64(0.8221651884161385), np.float64(0.1694196237129532), np.float64(0.09471884254812613), np.float64(0.12649055014954247), np.float64(0.2212818623223308), np.float64(0.364280816474159), np.float64(0.5949449599068163), np.float64(0.6950056709632189)]\n",
      "Validation F1-score: 0.411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.53      0.57      4159\n",
      "         1.0       0.92      0.54      0.68     97031\n",
      "         2.0       0.18      0.49      0.27     22970\n",
      "         3.0       0.70      0.84      0.76     49505\n",
      "         4.0       0.70      0.42      0.52     16093\n",
      "         5.0       0.22      0.02      0.04      1404\n",
      "         6.0       0.08      0.06      0.07        33\n",
      "         7.0       0.27      0.64      0.38       156\n",
      "\n",
      "    accuracy                           0.60    191351\n",
      "   macro avg       0.46      0.44      0.41    191351\n",
      "weighted avg       0.74      0.60      0.63    191351\n",
      "\n",
      "OVR_Random Forest...\n",
      "Params: {'max_depth': 6, 'class_weight': 'balanced'}\n",
      "Train F1-score: 0.334\n",
      "Thresholds: [np.float64(0.5001605083435355), np.float64(0.19553603977688613), np.float64(0.23918216453801278), np.float64(0.19918655570276259), np.float64(0.2306257939407484), np.float64(0.2567399405670618), np.float64(0.22222356362881063), np.float64(0.22989442378099417)]\n",
      "Validation F1-score: 0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.02      0.05      4159\n",
      "         1.0       0.85      0.97      0.90     97031\n",
      "         2.0       0.40      0.07      0.12     22970\n",
      "         3.0       0.68      0.92      0.78     49505\n",
      "         4.0       0.73      0.39      0.51     16093\n",
      "         5.0       0.06      0.00      0.00      1404\n",
      "         6.0       0.00      0.00      0.00        33\n",
      "         7.0       0.12      0.65      0.20       156\n",
      "\n",
      "    accuracy                           0.77    191351\n",
      "   macro avg       0.45      0.38      0.32    191351\n",
      "weighted avg       0.73      0.77      0.72    191351\n",
      "\n",
      "Best params for Random Forest:\n",
      "--------------------------------------------------\n",
      "Testing combinations for CatBoost...\n",
      "0:\tlearn: 0.6714918\ttotal: 322ms\tremaining: 5m 21s\n",
      "10:\tlearn: 0.5102173\ttotal: 3.01s\tremaining: 4m 30s\n",
      "20:\tlearn: 0.4106583\ttotal: 5.64s\tremaining: 4m 22s\n",
      "30:\tlearn: 0.3454460\ttotal: 8.56s\tremaining: 4m 27s\n",
      "40:\tlearn: 0.3013963\ttotal: 11.6s\tremaining: 4m 30s\n",
      "50:\tlearn: 0.2708647\ttotal: 14.5s\tremaining: 4m 29s\n",
      "60:\tlearn: 0.2491734\ttotal: 17.5s\tremaining: 4m 29s\n",
      "70:\tlearn: 0.2334795\ttotal: 20.2s\tremaining: 4m 24s\n",
      "80:\tlearn: 0.2218651\ttotal: 22.9s\tremaining: 4m 19s\n",
      "90:\tlearn: 0.2133432\ttotal: 25.4s\tremaining: 4m 14s\n",
      "100:\tlearn: 0.2070188\ttotal: 28s\tremaining: 4m 9s\n",
      "110:\tlearn: 0.2018186\ttotal: 30.7s\tremaining: 4m 5s\n",
      "120:\tlearn: 0.1980487\ttotal: 33.3s\tremaining: 4m 1s\n",
      "130:\tlearn: 0.1947837\ttotal: 35.9s\tremaining: 3m 57s\n",
      "140:\tlearn: 0.1920578\ttotal: 38.5s\tremaining: 3m 54s\n",
      "150:\tlearn: 0.1899683\ttotal: 41.1s\tremaining: 3m 51s\n",
      "160:\tlearn: 0.1880297\ttotal: 43.7s\tremaining: 3m 47s\n",
      "170:\tlearn: 0.1862857\ttotal: 46.2s\tremaining: 3m 44s\n",
      "180:\tlearn: 0.1848988\ttotal: 48.8s\tremaining: 3m 40s\n",
      "190:\tlearn: 0.1836416\ttotal: 51.3s\tremaining: 3m 37s\n",
      "200:\tlearn: 0.1825817\ttotal: 53.8s\tremaining: 3m 33s\n",
      "210:\tlearn: 0.1814789\ttotal: 56.4s\tremaining: 3m 30s\n",
      "220:\tlearn: 0.1806259\ttotal: 58.9s\tremaining: 3m 27s\n",
      "230:\tlearn: 0.1798876\ttotal: 1m 1s\tremaining: 3m 24s\n",
      "240:\tlearn: 0.1790640\ttotal: 1m 4s\tremaining: 3m 21s\n",
      "250:\tlearn: 0.1783316\ttotal: 1m 6s\tremaining: 3m 19s\n",
      "260:\tlearn: 0.1777363\ttotal: 1m 9s\tremaining: 3m 16s\n",
      "270:\tlearn: 0.1771806\ttotal: 1m 12s\tremaining: 3m 14s\n",
      "280:\tlearn: 0.1766759\ttotal: 1m 14s\tremaining: 3m 10s\n",
      "290:\tlearn: 0.1761847\ttotal: 1m 17s\tremaining: 3m 8s\n",
      "300:\tlearn: 0.1756569\ttotal: 1m 19s\tremaining: 3m 5s\n",
      "310:\tlearn: 0.1751674\ttotal: 1m 22s\tremaining: 3m 2s\n",
      "320:\tlearn: 0.1747199\ttotal: 1m 25s\tremaining: 3m\n",
      "330:\tlearn: 0.1743614\ttotal: 1m 27s\tremaining: 2m 57s\n",
      "340:\tlearn: 0.1739688\ttotal: 1m 30s\tremaining: 2m 54s\n",
      "350:\tlearn: 0.1736034\ttotal: 1m 32s\tremaining: 2m 51s\n",
      "360:\tlearn: 0.1732499\ttotal: 1m 35s\tremaining: 2m 49s\n",
      "370:\tlearn: 0.1728726\ttotal: 1m 38s\tremaining: 2m 46s\n",
      "380:\tlearn: 0.1725040\ttotal: 1m 40s\tremaining: 2m 43s\n",
      "390:\tlearn: 0.1721640\ttotal: 1m 43s\tremaining: 2m 40s\n",
      "400:\tlearn: 0.1718681\ttotal: 1m 45s\tremaining: 2m 37s\n",
      "410:\tlearn: 0.1715469\ttotal: 1m 48s\tremaining: 2m 35s\n",
      "420:\tlearn: 0.1712495\ttotal: 1m 50s\tremaining: 2m 32s\n",
      "430:\tlearn: 0.1709917\ttotal: 1m 53s\tremaining: 2m 29s\n",
      "440:\tlearn: 0.1707406\ttotal: 1m 56s\tremaining: 2m 27s\n",
      "450:\tlearn: 0.1705097\ttotal: 1m 58s\tremaining: 2m 24s\n",
      "460:\tlearn: 0.1702240\ttotal: 2m 1s\tremaining: 2m 21s\n",
      "470:\tlearn: 0.1699699\ttotal: 2m 3s\tremaining: 2m 19s\n",
      "480:\tlearn: 0.1696908\ttotal: 2m 6s\tremaining: 2m 16s\n",
      "490:\tlearn: 0.1694769\ttotal: 2m 8s\tremaining: 2m 13s\n",
      "500:\tlearn: 0.1692692\ttotal: 2m 11s\tremaining: 2m 11s\n",
      "510:\tlearn: 0.1690250\ttotal: 2m 14s\tremaining: 2m 8s\n",
      "520:\tlearn: 0.1688172\ttotal: 2m 16s\tremaining: 2m 5s\n",
      "530:\tlearn: 0.1686341\ttotal: 2m 19s\tremaining: 2m 3s\n",
      "540:\tlearn: 0.1684458\ttotal: 2m 22s\tremaining: 2m\n",
      "550:\tlearn: 0.1682645\ttotal: 2m 24s\tremaining: 1m 57s\n",
      "560:\tlearn: 0.1680816\ttotal: 2m 27s\tremaining: 1m 55s\n",
      "570:\tlearn: 0.1678673\ttotal: 2m 29s\tremaining: 1m 52s\n",
      "580:\tlearn: 0.1676924\ttotal: 2m 32s\tremaining: 1m 49s\n",
      "590:\tlearn: 0.1675159\ttotal: 2m 34s\tremaining: 1m 47s\n",
      "600:\tlearn: 0.1673093\ttotal: 2m 37s\tremaining: 1m 44s\n",
      "610:\tlearn: 0.1671435\ttotal: 2m 40s\tremaining: 1m 42s\n",
      "620:\tlearn: 0.1669739\ttotal: 2m 43s\tremaining: 1m 39s\n",
      "630:\tlearn: 0.1667942\ttotal: 2m 45s\tremaining: 1m 37s\n",
      "640:\tlearn: 0.1666645\ttotal: 2m 48s\tremaining: 1m 34s\n",
      "650:\tlearn: 0.1664978\ttotal: 2m 51s\tremaining: 1m 31s\n",
      "660:\tlearn: 0.1663411\ttotal: 2m 53s\tremaining: 1m 29s\n",
      "670:\tlearn: 0.1661574\ttotal: 2m 56s\tremaining: 1m 26s\n",
      "680:\tlearn: 0.1660068\ttotal: 2m 59s\tremaining: 1m 23s\n",
      "690:\tlearn: 0.1658300\ttotal: 3m 1s\tremaining: 1m 21s\n",
      "700:\tlearn: 0.1657124\ttotal: 3m 4s\tremaining: 1m 18s\n",
      "710:\tlearn: 0.1655928\ttotal: 3m 6s\tremaining: 1m 15s\n",
      "720:\tlearn: 0.1654660\ttotal: 3m 9s\tremaining: 1m 13s\n",
      "730:\tlearn: 0.1653272\ttotal: 3m 12s\tremaining: 1m 10s\n",
      "740:\tlearn: 0.1651715\ttotal: 3m 14s\tremaining: 1m 8s\n",
      "750:\tlearn: 0.1650259\ttotal: 3m 17s\tremaining: 1m 5s\n",
      "760:\tlearn: 0.1648992\ttotal: 3m 20s\tremaining: 1m 2s\n",
      "770:\tlearn: 0.1647724\ttotal: 3m 22s\tremaining: 1m\n",
      "780:\tlearn: 0.1646372\ttotal: 3m 25s\tremaining: 57.6s\n",
      "790:\tlearn: 0.1645262\ttotal: 3m 28s\tremaining: 55s\n",
      "800:\tlearn: 0.1644037\ttotal: 3m 30s\tremaining: 52.3s\n",
      "810:\tlearn: 0.1642743\ttotal: 3m 33s\tremaining: 49.7s\n",
      "820:\tlearn: 0.1641640\ttotal: 3m 36s\tremaining: 47.1s\n",
      "830:\tlearn: 0.1640553\ttotal: 3m 38s\tremaining: 44.5s\n",
      "840:\tlearn: 0.1639318\ttotal: 3m 41s\tremaining: 41.9s\n",
      "850:\tlearn: 0.1637948\ttotal: 3m 44s\tremaining: 39.3s\n",
      "860:\tlearn: 0.1636701\ttotal: 3m 47s\tremaining: 36.7s\n",
      "870:\tlearn: 0.1635683\ttotal: 3m 49s\tremaining: 34s\n",
      "880:\tlearn: 0.1634789\ttotal: 3m 52s\tremaining: 31.4s\n",
      "890:\tlearn: 0.1633619\ttotal: 3m 55s\tremaining: 28.8s\n",
      "900:\tlearn: 0.1632313\ttotal: 3m 58s\tremaining: 26.2s\n",
      "910:\tlearn: 0.1631102\ttotal: 4m 1s\tremaining: 23.6s\n",
      "920:\tlearn: 0.1630078\ttotal: 4m 3s\tremaining: 20.9s\n",
      "930:\tlearn: 0.1629156\ttotal: 4m 6s\tremaining: 18.3s\n",
      "940:\tlearn: 0.1628342\ttotal: 4m 9s\tremaining: 15.6s\n",
      "950:\tlearn: 0.1627513\ttotal: 4m 12s\tremaining: 13s\n",
      "960:\tlearn: 0.1626659\ttotal: 4m 14s\tremaining: 10.3s\n",
      "970:\tlearn: 0.1625902\ttotal: 4m 17s\tremaining: 7.69s\n",
      "980:\tlearn: 0.1625043\ttotal: 4m 20s\tremaining: 5.05s\n",
      "990:\tlearn: 0.1624017\ttotal: 4m 23s\tremaining: 2.39s\n",
      "999:\tlearn: 0.1623283\ttotal: 4m 25s\tremaining: 0us\n",
      "CatBoost...\n",
      "Params: {'iterations': 1000, 'depth': 6, 'boosting_type': 'Ordered', 'auto_class_weights': 'SqrtBalanced', 'loss_function': 'MultiClassOneVsAll'}\n",
      "Train F1-score: 0.563\n",
      "Thresholds: [np.float64(0.5957739630957768), np.float64(0.2448121817293811), np.float64(0.24951239392854854), np.float64(0.27705229879403714), np.float64(0.3876119726164087), np.float64(0.32225701963563297), np.float64(0.5412731424098816), np.float64(0.5978394748282143)]\n",
      "Validation F1-score: 0.499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.55      0.60      4159\n",
      "         1.0       0.86      0.96      0.91     97031\n",
      "         2.0       0.43      0.16      0.24     22970\n",
      "         3.0       0.75      0.83      0.79     49505\n",
      "         4.0       0.67      0.64      0.65     16093\n",
      "         5.0       0.21      0.16      0.18      1404\n",
      "         6.0       0.50      0.09      0.15        33\n",
      "         7.0       0.40      0.58      0.47       156\n",
      "\n",
      "    accuracy                           0.79    191351\n",
      "   macro avg       0.56      0.50      0.50    191351\n",
      "weighted avg       0.76      0.79      0.76    191351\n",
      "\n",
      "Best params for CatBoost:\n",
      "--------------------------------------------------\n",
      "Testing combinations for Neural Network...\n",
      "Iteration 1, loss = 0.64885839\n",
      "Iteration 2, loss = 0.61480686\n",
      "Iteration 3, loss = 0.60718672\n",
      "Iteration 4, loss = 0.60321479\n",
      "Iteration 5, loss = 0.60038016\n",
      "Iteration 6, loss = 0.59731431\n",
      "Iteration 7, loss = 0.59602401\n",
      "Iteration 8, loss = 0.59478555\n",
      "Iteration 9, loss = 0.59348128\n",
      "Iteration 10, loss = 0.59334436\n",
      "Iteration 11, loss = 0.59363767\n",
      "Iteration 12, loss = 0.59292107\n",
      "Iteration 13, loss = 0.59173180\n",
      "Iteration 14, loss = 0.59225000\n",
      "Iteration 15, loss = 0.59207689\n",
      "Iteration 16, loss = 0.59195638\n",
      "Iteration 17, loss = 0.59199476\n",
      "Iteration 18, loss = 0.59112271\n",
      "Iteration 19, loss = 0.59128366\n",
      "Iteration 20, loss = 0.59076011\n",
      "Iteration 21, loss = 0.59143805\n",
      "Iteration 22, loss = 0.59036533\n",
      "Iteration 23, loss = 0.59078075\n",
      "Iteration 24, loss = 0.59091834\n",
      "Iteration 25, loss = 0.59009308\n",
      "Iteration 26, loss = 0.58984273\n",
      "Iteration 27, loss = 0.59024728\n",
      "Iteration 28, loss = 0.59028990\n",
      "Iteration 29, loss = 0.58976598\n",
      "Iteration 30, loss = 0.58975484\n",
      "Iteration 31, loss = 0.59033257\n",
      "Iteration 32, loss = 0.58944642\n",
      "Iteration 33, loss = 0.59009435\n",
      "Iteration 34, loss = 0.59013137\n",
      "Iteration 35, loss = 0.59065207\n",
      "Iteration 36, loss = 0.58996954\n",
      "Iteration 37, loss = 0.58982757\n",
      "Iteration 38, loss = 0.58931651\n",
      "Iteration 39, loss = 0.58952896\n",
      "Iteration 40, loss = 0.58970254\n",
      "Iteration 41, loss = 0.58945261\n",
      "Iteration 42, loss = 0.58945812\n",
      "Iteration 43, loss = 0.58994306\n",
      "Iteration 44, loss = 0.58997972\n",
      "Iteration 45, loss = 0.58977982\n",
      "Iteration 46, loss = 0.58947759\n",
      "Iteration 47, loss = 0.58956150\n",
      "Iteration 48, loss = 0.58969719\n",
      "Iteration 49, loss = 0.58935219\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Neural Network...\n",
      "Params: {'hidden_layer_sizes': (25, 8), 'learning_rate_init': 0.01}\n",
      "Train F1-score: 0.448\n",
      "Thresholds: [np.float64(0.23784561870084858), np.float64(0.49824826952995227), np.float64(0.16548628639947088), np.float64(0.361068553966379), np.float64(0.4100987156736129), np.float64(0.11306525397481286), np.float64(0.004002292697920989), np.float64(0.2802359509148219)]\n",
      "Validation F1-score: 0.449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.48      0.56      4159\n",
      "         1.0       0.87      0.92      0.90     97031\n",
      "         2.0       0.34      0.22      0.27     22970\n",
      "         3.0       0.73      0.83      0.78     49505\n",
      "         4.0       0.65      0.58      0.61     16093\n",
      "         5.0       0.20      0.06      0.10      1404\n",
      "         6.0       0.00      0.00      0.00        33\n",
      "         7.0       0.64      0.27      0.38       156\n",
      "\n",
      "    accuracy                           0.77    191351\n",
      "   macro avg       0.51      0.42      0.45    191351\n",
      "weighted avg       0.74      0.77      0.75    191351\n",
      "\n",
      "Best params for Neural Network:\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_splits = 3\n",
    "stratified_kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "X = df[naive_features]\n",
    "y = df[ordinal_target]\n",
    "\n",
    "X.columns\n",
    "\n",
    "y.value_counts(normalize=True)\n",
    "models_params = []\n",
    "for i, (train_index, val_index) in enumerate(stratified_kf.split(X, y), start=1):\n",
    "    print(f\"Starting CV_{i}/3 for {ordinal_target}...\")\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    #--------------- Target Ordinal Encoding \n",
    "        \n",
    "\n",
    "    print(f\"Ordinal encoding...\")\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_val_encoded = X_val.copy()\n",
    "    for cat in cat_feats:\n",
    "        X_train_encoded, X_val_encoded, ordinal_mapping = target_guided_ordinal_encoding(X_train_encoded, X_val_encoded, cat, ordinal_target, y_train, 1)\n",
    "\n",
    "    \n",
    "    columns = X_train_encoded.columns\n",
    "\n",
    "    \n",
    "    # --------------- Frequency Encoding\n",
    "    print(f\"Frequency encoding...\")\n",
    "    for cat in cat_feats:\n",
    "        X_train_encoded, X_val_encoded, freq_map = frequency_encoding(X_train_encoded, X_val_encoded, cat)\n",
    "\n",
    "    \n",
    "    X_train_encoded  = X_train_encoded[selected_features]\n",
    "    X_val_encoded = X_val_encoded[selected_features]\n",
    "    \n",
    "    \n",
    "    # --------------- Imputing missing values\n",
    "    print(f\"Impuiting missing values...\")\n",
    "    X_train_imputed, X_val_imputed = num_imputing(X_train_encoded, X_val_encoded)\n",
    "        \n",
    "    for clf_name, clf, param_grid in models:\n",
    "        # -------------- Scaling and Normalizing for some models\n",
    "        if clf_name in [\"Logistic Regression\", \"KNNC\", \"Neural Network\", \"NB\", \"SVC\"]:\n",
    "            X_train_imputed, X_val_imputed = num_scaling(X_train_imputed, X_val_imputed)\n",
    "        \n",
    "\n",
    "        # -------------- Get the possible combinations of hyperparameters for each model\n",
    "        print(f\"Testing combinations for {clf_name}...\")\n",
    "        scores_dict = {}\n",
    "\n",
    "        if param_grid:\n",
    "            keys, values = zip(*param_grid.items())\n",
    "            for combination in itertools.product(*values):\n",
    "                params = dict(zip(keys, combination))\n",
    "                if params:\n",
    "                    if clf_name == \"CatBoost\":\n",
    "                        clf = CatBoostClassifier(**params, verbose=10)\n",
    "                    else:\n",
    "                        clf.set_params(**params)\n",
    "                    clf.fit(X_train_imputed, y_train)\n",
    "                    params, train_score, val_score = model_predictions_global(X_train_imputed, y_train, X_val_imputed, y_val, clf, clf_name, ordinal_target, i, params)\n",
    "                    scores_dict[(clf_name, tuple(params.items()))] = val_score\n",
    "                models_params.append({\n",
    "                    \"clf_name\": clf_name,\n",
    "                    \"CV\":f\"CV_{i}\",\n",
    "                    \"params\": params,\n",
    "                    \"train_score\": train_score,\n",
    "                    \"validation_score\": val_score})\n",
    "                \n",
    "                # ----------- OvRClassifier for the model\n",
    "                if clf_name == \"Random Forest\":\n",
    "                    clf.set_params(**params)\n",
    "                    clf_ovr = OneVsRestClassifier(clf)\n",
    "                    clf_ovr.fit(X_train_imputed, y_train)\n",
    "                    params, train_score, val_score = model_predictions_global(X_train_imputed, y_train, X_val_imputed, y_val, clf_ovr, f\"OVR_{clf_name}\", ordinal_target, i, params)\n",
    "                    scores_dict[(f\"OVR_{clf_name}\", tuple(params.items()))] = val_score\n",
    "                    models_params.append({\n",
    "                        \"clf_name\": f\"OVR_{clf_name}\",\n",
    "                        \"CV\":f\"CV_{i}\",\n",
    "                        \"params\": params,\n",
    "                        \"train_score\": train_score,\n",
    "                        \"validation_score\": val_score})\n",
    "                    \n",
    "        best_params, best_score = max(scores_dict.items(), key=lambda x: x[1])\n",
    "        print(f\"Best params for {clf_name}:\")\n",
    "        \n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "    print(\"--------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_name\n",
      "CatBoost               0.486894\n",
      "Neural Network         0.446874\n",
      "Random Forest          0.405191\n",
      "Logistic Regression    0.395470\n",
      "NB                     0.317412\n",
      "OVR_Random Forest      0.313638\n",
      "Name: validation_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(models_params) \n",
    "\n",
    "mean_val_scores = results.groupby('clf_name')['validation_score'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(mean_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_val_scores.plot(kind='bar', figsize=(12, 6), title=\"Mean Validation Scores by Classifier (3-fold CV)\")\n",
    "plt.xlabel(\"Classifier\")\n",
    "plt.ylabel(\"Mean Validation Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
